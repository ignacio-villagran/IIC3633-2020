Cremonesi et al., (2010) aborda la problemática de que las medidas orientadas a mejorar las métricas de precisión o error comúnmente usadas (RMSE) no necesariamente repercuten en una mejora en la precisión de las tareas de recomendación en el caso de top-N. Es por esto, que se planteó el objetivo de proponer alternativas prácticas de dos algoritmos de filtrado colaborativo que superan a otros algoritmos respecto a la tarea de recomendación de top-N, esto evaluando la precisión de los algoritmos de recomendación. Dada la simplicidad de las alternativas propuestas, la especificidad de su contribución en métricas de precisión, construcción específica de un test set y la presentación de los mismos algoritmos hacen de este artículo un manuscrito muy interesante de discutir en el contexto del rendimiento de un sistema recomendador. 
la problemática se expone en forma concreta, destacando los problemas de precisión cuándo se utilizan métricas como el RMSE para la construcción de un algoritmo de recomendación.

En primer lugar, en la metodología verificamos que se utiliza únicamente el feedback de los usuarios respecto a la valoración máxima que entregan sobre el contenido, lo que reduce en un 73% el número de valoraciones disponibles para validación (Netflix). Esta perdida de datos, que hemos visto en lecturas anteriores, debe ser tratada con cuidado debido a sus limitaciones en la transferencia a otros sistemas que no cuentan con un gran número de valoraciones y menos aún valoraciones máximas.  El componente innovador de la metodología descrita radica en que utiliza como indicadores de calidad las métricas dicotómicas “recall” y “precisión”. Un aspecto importante es que se seleccionaron al azar artículos no calificados por el usuario, donde se “asume” que la mayoría no era de interés, lo cual puede llevar a sesgo, pero se entiende que es parte de las limitaciones de trabajar con valoraciones o calificaciones y se declara correctamente en el artículo. La fortaleza de la metodología está en la construcción específica del dataset de testeo en dos subsets que representan el componente “popular” y “no popular” de la distribución de los datos. 

Los resultados obtenidos fueron bastante interesantes, donde podemos destacar que en ambos dataset, independientemente de la cantidad de elementos populares, el algoritmo propuesto PureSVD es el de mejor rendimiento. También fue relevante analizar el comportamiento del algoritmo (no personalizado) Top-Pop, el cual tiene un excelente rendimiento en la base de datos total, pero cae en forma importante cuando se quitan los no populares, demostrando el sesgo de utilizar este tipo de algoritmos y de analizar sólo la base completa. Finalmente, la ampliamente utilizada correlación basada en vecinos cercanos, esta demuestra ser uno de los algoritmos con mayor rendimiento cuando se concentra en el conjunto de datos menos populares, inverso a los otros algoritmos. Es por esto que los autores atribuyen a la amplia aceptación de este enfoque a la importancia de los elementos de no populares en sistemas recomendadores.

En concordancia con la opinión de los autores, uno de los hallazgos más interesantes que se producen como resultado de la desconstrucción de la base de datos de testeo en PureSVD fue que la precisión mejora al aumentar la dimensionalidad. Esto releva la importancia de explorar los datos en primera instancia para luego tomar una decisión respecto al número de factores dependiendo de la cantidad de elementos populares presentes en la base de datos. Respecto a la problemática de datos perdidos que mencioné al inicio, los autores concluyen que las medidas propuestas para medir precisión en este artículo debieran funcionar mejor ya que involucran todos los elementos posibles para la fase de validación del algoritmo. A esto, los autores le atribuyen el mejor rendimiento, sin embargo, faltaría un análisis un poco más concreto para apoyar esta conclusión ya que también pueden ser otros factores de la metodología propuesta que expliquen de mejor forma estos resultados. 

En conclusión, creo que este artículo aporta sustancialmente a la discusión de ventajas y desventajas de la mayoría de los artículos revisados previamente, realizando breves definiciones introductorias para cada tema lo que ayuda bastante a la comprensión del lector. Los resultados del artículo, en mi opinión, son coherentes con las problemáticas expuestas, ofreciendo una alternativa simple y no desconocida como solución. Como aspecto a mejorar, un estudio de correlación en diferentes contextos de información entre las métricas de precisión propuestas y las de estimación de error comúnmente utilizadas sería relevante para calcular con exactitud las diferencias y determinar su potencialidad. 
