En el artículo de Rendle et al. (2009), el objetivo fue explorar respecto a situaciones de recomendación de productos desde información basada en experiencias o comportamiento de los usuarios (feedback implícito). Se presenta un criterio de optimización genérico BPR-OPT con un método de aprendizaje del modelo que integra un algoritmo estocástico basado en gradiente descendiente con técnica de muestreo bootstrap. Este método se ejemplifica en el modelo de factorización matricial (FM) y de k vecinos cercanos (kNN) que son los más comúnmente utilizados para recomendación y luego se comparan con otros enfoques utilizados en estos mismos modelos y con el método no personalizado most-popular. 

Según lo revisado, la problemática queda muy bien expresada y se sustenta en la pregunta ¿Qué hago con los datos perdidos o faltantes? Históricamente, en estadística estos datos se eliminaban u omitían, sin embargo, sabemos que eso puede llevar a un gran error de análisis y generalización del modelo. Respecto a los modelos de aprendizaje automático para recomendadores, estos no son capaces de aprender algo al tener datos faltantes, teniendo todos estos valores una connotación negativa en el algoritmo de aprendizaje durante el entrenamiento llevando a un sobreajuste y predicción sólo negativa, para lo que comúnmente se utiliza la regularización.  

Algo positivo de este artículo, es que los autores destacan lo diferente de este trabajo respecto a otros métodos por qué otros métodos de regularización y optimización descritos en la literatura. La ventaja del enfoque propuesto es la utilización de pares de ítems como datos de insumo para el entrenamiento y optimización para clasificar en forma asertiva los pares de ítems en vez de puntuar o valorar los ítems en forma individual, ya que eso representa mejor el problema comparado con reemplazar los valores perdidos por valores negativos. Lo novedoso, es que se realizan pares heterogéneos, donde se busca una relación de superioridad respecto a preferencia de un ítem sobre otro. 

Respecto al enfoque propuesto, se deriva un método genérico que consiste en el criterio general de optimización para este tipo de clasificaciones (BPR-OPT). Además, los autores proponen un algoritmo LearnBPR como modelo de aprendizaje para BPR-OPT. Este es un algoritmo estocástico basado en el descenso de gradiente con muestreo tipo bootstrap. Al analizar esto en detalle, se justifica adecuadamente esta forma de muestreo versus el uso de gradiente completa ya que en esta última puede tener poco aprendizaje por una posible carga uniltaral de dominancia en la relación y una regularización  dificultosa cuando las gradientes difieren mucho entre si llevando a probable sobreajuste. Por otro lado, pude inferir que el uso de gradiente descendente estocástica se hace cargo de este problema eligiendo en forma aleatoria los datos para el entrenamiento buscando una distribución uniforme a través de un remuestreo (bootstraping), sin embargo, habría sido positivo una mejor descripción de esta técnica de remuestreo y su aplicación concreta al modelo. Finalmente, para la evaluación se utilizaron dos bases de datos, los modelos se entrenaron, aprendieron en base a este esquema y realizaron la calificación personalizada la cual se evaluó con el set de prueba según la variable de área bajo la curva (mayor valor mejor calidad de predicción). 

Como principales aprendizajes, creo que el modelo propuesto destaca por no subvalorar los valores perdidos a través del análisis de conjunto de ítems con las técnicas de Bootstraping y esto se ve reflejado en los experimentos. Además, según los resultados de la evaluación y el área bajo la curva, los dos métodos optimizados de BPR superan a todos los demás métodos en calidad de predicción y también el método no-personalizado most-popular, probablemente por sobreajuste de los otros modelos al momento de buscar aprendizaje de este, a pesar de que algunos incluían la regularización. Creo que lo fundamental para demostrar superioridad fue el clasificar en base a conjuntos de datos heterogéneos, destacando la importancia de optimizar los parámetros de los modelos basado en un criterio adecuado.  
