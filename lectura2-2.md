En el artículo de Rendle et al. (2009), el objetivo fue explorar respecto a situaciones de recomendación de productos desde información basada en experiencias o comportamiento de los usuarios (feedback implícito). Se presenta un criterio de optimización genérico BPR-OPT con un método de aprendizaje del modelo que integra un algoritmo estocástico basado en gradiente descendiente con técnica de muestreo bootstrap. Este método se ejemplifica en el modelo de factorización matricial (FM) y de k vecinos cercanos (kNN) que son los más comúnmente utilizados para recomendación y luego se comparan con otros enfoques utilizados en estos mismos modelos y con el método no personalizado most-popular. 

Según lo revisado, la problemática queda muy bien expresada y se sustenta en la pregunta ¿Qué hago con los datos perdidos o faltantes? Históricamente, en estadística estos datos se eliminaban u omitían, sin embargo, sabemos que eso puede llevar a un gran error de análisis y generalización del modelo. Respecto a los modelos de aprendizaje automático para recomendadores, estos no son capaces de aprender algo al tener datos faltantes, teniendo todos estos valores una connotación negativa en el algoritmo de aprendizaje durante el entrenamiento llevando a un sobreajuste y predicción sólo negativa, para lo que comúnmente se utiliza la regularización.  

Algo positivo de este artículo, es que los autores destacan lo diferente de este trabajo respecto a otros métodos por qué otros métodos de regularización y optimización descritos en la literatura. La ventaja del enfoque propuesto es la utilización de pares de ítems como datos de insumo para el entrenamiento y optimización para clasificar en forma asertiva los pares de ítems en vez de puntuar o valorar los ítems en forma individual, ya que eso representa mejor el problema comparado con reemplazar los valores perdidos por valores negativos. Lo novedoso, es que se realizan pares heterogéneos, donde se busca una relación de superioridad respecto a preferencia de un ítem sobre otro. 

Respecto al enfoque propuesto, se deriva un método genérico que consiste en el criterio general de optimización para este tipo de clasificaciones (BPR-OPT). Además, los autores proponen un algoritmo LearnBPR como modelo de aprendizaje para BPR-OPT. Este es un algoritmo estocástico basado en el descenso de gradiente con muestreo tipo bootstrap. Al analizar esto en detalle, se justifica adecuadamente esta forma de muestreo versus el uso de gradiente completa ya que en esta última puede tener poco aprendizaje por una posible carga unilateral de dominancia en la relación y una regularización  dificultosa cuando las gradientes difieren mucho entre si llevando a probable sobreajuste. Por otro lado, pude inferir que el uso de gradiente descendente estocástica se hace cargo de este problema eligiendo en forma aleatoria los datos para el entrenamiento buscando una distribución uniforme a través de un remuestreo (bootstraping).

Como aspectos a mejorar, habría sido positivo una mejor descripción de esta técnica de remuestreo y su aplicación concreta al modelo. Otro modelo estadístico que habría sido positivo profundizar es el de área bajo la curva ROC, indicador para de la calidad de predicción en este caso. Esta estrategia estadística fue utilizada para la evaluación con dos bases de datos para evaluar la calificación personalizada con el set de prueba.

Como principales aprendizajes, creo que el modelo propuesto destaca por no subvalorar los valores perdidos a través del análisis de conjunto de ítems con las técnicas de Bootstraping y esto se ve reflejado en los experimentos. Además, se pudo comprobar superioridad de esta estrategia según los resultados de la evaluación y el área bajo la curva frente a todos los demás métodos en calidad de predicción y también el método no-personalizado most-popular, probablemente por sobreajuste de los otros modelos al momento de buscar aprendizaje de este, a pesar de que algunos incluían la regularización. Creo que lo fundamental para demostrar superioridad fue el clasificar en base a conjuntos de datos heterogéneos, destacando la importancia de optimizar los parámetros de los modelos basado en un criterio adecuado.  
