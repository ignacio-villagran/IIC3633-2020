**Parra, D., Brusilovsky, P., and Trattner, C. (2014). See What You Want to See: Visual User-Driven Approach for Hybrid Recommendation. *International Conference on Intelligent User Interfaces, Proceedings IUI*.**

Parra et al., (2014) es un artículo centrado en el usuario. Este estudio se basa en la problemática de que no siempre las métricas de exactitud se relacionan con una mejor experiencia de usuario. Es por esto, que se propone SetFusion, una interfaz visual que empodera al usuario y le permite controlar manualmente por el usuario las estrategias de recomendación en base a sus intereses y evaluación de resultados. Para esto, se describen los resultados de dos estudios aplicados en el contexto de un sistema de recomendación de conferencias. Los resultados son positivos y demuestran efectividad en este sistema controlado por el usuario. 

Al analizar la problemática, los autores la fundamentan en forma precisa y acotada en dos enfoques, lo que, sin duda ayuda para entender la coherencia de la solución propuesta presentada en el paper. Primero, las recomendaciones basadas en input visuales. Donde, si bien se han reportado algunos ejemplos positivos en la literatura, aún hay aspectos a mejorar respecto a la complejidad innecesaria a la cual se ven enfrentados los usuarios en términos de entendimiento. Para mejorar esto, se propone el diagrama de Venn para mejorar el control de los usuarios. Segundo,  el contexto de sistemas de recomendación para charlas o artículos de investigación. Donde se han reportado diferentes enfoques y métodos, destacando algoritmos de filtrado collaborativo sobre  algoritmos basados en contenido o métodos híbridos que combinan ambos.  El artículo destaca por explicar en detalle y también a través de ilustraciones la interfaz SetFusion y sus interacciones. Lo anterior es  muy positivo ya que favorece el entendimiento de las ventajas que esta propuesta presenta frente a la problemática planteada. 

Respecto a los algoritmos de recomendación propuestos, se utilizaron tres. El primero basado en contenido, donde el usuario es representado como un vector con sus palabras claves y que se extrae desde el título y abstract que el usuario ha marcado de conferencias actuales o previas de la página. Ante esto, nace la inquietud de qué pasa con los usuarios nuevos que no tienen preferencias o la variabilidad de experiencia que puede tener un usuario frente a otro. El segundo es recomendación basado en popularidad del autor. En este método ordenaron los artículos considerando el número de citas que cada autor recibe en la ACM Digital Library, filtrados por los que se realizaron en el contexto del navegador de charlas de investigación que se está probando. Es importante destacar, que no se describen posibles mitigantes a posibles errores que pueden aparecer, por ejemplo autores con nombres similares, o por el contrario, nombres duplicados o que están escritos de diferente forma. Por otro lado, no se describe el número de artículos utilizados o que cumplían con las características de estar presente en el navegador utilizado o cuánto porcentaje representaba de la base de datos total.  En tercer lugar, recomendación basada en popularidad de artículos marcados o destacados. Esto es una recomendación no personalizada con enfoque basado en la comunidad, donde se ordenan los artículos según popularidad ajustado según el número de personas que integran la comunidad donde la conferencia se presentó. Éste último artículo pareciera tener semejanzas con algoritmos MostPopular, donde no existe personalización. 

Lo que más se destaca del artículo, es que se realizan estudios con usuarios. En ese sentido, es muy interesante la realización y reporte de un estudio piloto. Dado el enfoque del artículo propuesto, el estudio piloto es una parte fundamental de la metodología, ayudando a identificar aspectos importantes a mejorar previo al estudio con mayor cantidad de usuarios. Por otro lado, se reporta que en este estudio los usuarios debían seleccionar sus autores favoritos de conferencias previas y seleccionar los mejores artículos de los autores. Si bien pareciera ser una selección que entregara información valiosa, como se mencionó anteriormente no se identifica la posible barrera de un usuario nuevo que no tiene autores favoritos o conocidos y está empezando en el contexto de una temática de investigación específica. Asimismo, habría sido positivo describir cuáles fueron los aprendizajes y mejoras realizadas luego del estudio piloto. Otro aspecto importante, es que se describe que se invitó a participar a los usuarios vía correo electrónico. Sin embargo, no se detallan aspectos éticos o de confidencialidad de los datos. 

Otro aspecto positivo es que se realiza una síntesis del estudio previo el cual se utiliza como baseline y comparación, donde ese destaca la participación y se describen números comparables en la mayoría de los indicadores según el aumento reporte por parte de los usuarios. Sin embargo, se debe tener especial atención ya que no se describen las características generales de los usuarios que integran la base de datos, y que podrían permitir entender si los resultados son comparables, interpretables y disminuyen el error que la variabilidad usuaria puede entregar. Un aspecto interesante, fue el análisis del tiempo, donde se describe que mientras el total del tiempo destinado al trabajo con el sistema aumentó en conjunto con los otros parámetros, este aumento fue un poco menor en el número de artículos marcados o destacados, por lo tanto, los usuarios tuvieron la posibilidad de trabajar un poco más destinando menos tiempo por marcado, lo cual siempre va a generar una mejora en la percepción usuaria. 

En relación a la optimización en el desempeño de los usuarios, si bien se destacan diferencias positivas en las métricas de uso de las viñetas de deslizamiento, estas diferencias se podrían mejorar si se someten a una técnica estadística que pondere el tamaño y significancia de los cambios. Respecto al diagrama de Venn, también se describe una mejora en el comportamiento de los usuarios, la cual podría ser calculada en términos de diferencia estadística.  Por otro lado, se evaluó la percepción usuaria de SetFusion con una encuesta al finalizar  los testeos, donde si de destacan diferencias en términos de significancia estadística con una valoración positiva de los usuarios frente a las características visuales y controlables del método propuesto. 

A modo de conclusión, el estudio destaca por ser muy explicativo respecto a las características que hacen de SetFusion un método ventajoso en el contexto de recomendación de charlas y artículos de investigación, y también en las principales diferencias encontradas tanto en el comportamiento de los usuarios cuando interactuaban con estas características como en la percepción usuaria evaluada con una encuesta. También algo positivo es que se destacan muy concretamente cuáles son los aportes sustantivos en la discusión. Como aspecto a mejorar, sería agregar los aspectos éticos ya que se está trabajando con usuarios y su información, también optimizaría los análisis de diferencia de las métricas con alguna técnica de significancia estadística y también caracterizaría mejor la muestra de usuarios que participó en ambos estudios para así analizar la generalización de estos métodos en otros contextos con muestras similares. 
