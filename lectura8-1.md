

**Pu, P., Chen, L. and Hu, R. (2011). A user-centric evaluation framework for recommender systems. RecSys'11 - *Proceedings of the 5th ACM Conference on Recommender Systems*. 157-164.**

El estudio de Pu et al., (2011), proponen un artículo que analiza las propiedades psicométricas de un cuestionario sobre la experiencia de usuario con un sistema de recomendación considerando. Para esto se describe un marco de calificación denominado ResQue, que valora la calidad de la experiencia del usuario respecto a los elementos recomendados por el sistema, la usabilidad del mismo, su interfaz e interacción, satisfacción e influencia de las cualidades observadas en las intenciones de comportamiento de los usuarios. Los resultados indican que  ResQue provee validez y confiabilidad de sus mediciones y que existen relaciones causales entre sus constructos. 

En primer lugar, un aspecto muy positivo de este manuscrito, es la coherencia en la metodología propuesta para lograr centrar su artículo en la experiencia de los usuarios. Para esto, se utilizan variables propias de otras disciplinas, como el análisis psicométrico, para caracterizar los constructos medidos con los instrumentos de evaluación propuestos y que tienen como objetivo teórico medir la calidad del sistema de recomendación. El sistema propuesto, ResQue, destaca por su originalidad, orientación a la usabilidad e integración de características que han resultado ser positivas en estudios previos.

Durante el proceso de construcción de cuestionarios, es importante aprender de la literatura previa. En este manuscrito se destaca el uso de constructos ya reportados en estudios previos como base para la creación del modelo de evaluación unificado propuesto. También se describe el uso de la metodología Delphi para evaluar el contenido desde la perspectiva de un panel de expertos y actores clave, lo cual es positivo para revisar pertinencia de los ítems y corregir aspectos a mejorar antes de la aplicación general del instrumento. Respecto a este punto, una desventaja del artículo es que no caracteriza las personas que participan en este panel delphi ni tampoco las cuantifica. Esto es importante para valorar si es que se ajustan a criterios preestablecidos de esta metodología de validación de contenido. En la descripción el cuestionario, se destacan los aspectos clave que debieran estar presente en la medición de la calidad  de la recomendación, calidad de la interfaz, pertinencia de la interacción, suficiencia y explicabilidad de la información. Cada atributo es definido teóricamente, lo que facilita al lector respecto a las expectativas de los constructos que debieran aparecer de los resultados de la aplicación del cuestionario. Cabe destacar, que los autores buscan también medir actitudes dentro del modelo. Sin embargo, no queda claro si este constructo se construye desde la percepción reportada (satisfacción general y confianza) o debiera evaluarse más bien desde el comportamiento demostrado en la interacción con el sistema de recomendación. Las intenciones de comportamiento, a mi parecer, escapa de las percepciones usuarias y tienen más relación con objetivos procedimentales o de aplicación. Esto es reportado de igual forma por los autores, cuando definen esta dimensión en función de la influencia en la decisión de los usuarios por parte de sistema. El orden jerárquico del los constructos del modelo propuesto en la hipótesis me parece adecuado y se relaciona con tipologías de uso común para evaluación de programas donde primero se evalúa la reacción de los usuarios (percepción), luego el aprendizaje (creencias y actitudes), luego cambios en el comportamiento (intenciones de comportamiento) y luego debiera terminar en resultados y cambios organizacionales (Kirkpatrick & Kirkpatrick, 2008).

Para cumplir el objetivo de otorgar evidencia de validez a los resultados del instrumento de evaluación, se reportan los resultados en términos de consistencia interna (alfa de cronbach), correlación entre ítems, cargas factoriales , entre otros. Ante esto,  el artículo cumple con reportar la caracterización de la muestra, la matriz de correlación entre dimensiones.  Sin embargo, no se reporta un cálculo de tamaño muestral que me asegure que los análisis tienen menos error, además, existe un desbalance importante en género, con un 85% de mujeres integrando la muestra, y también existe heterogeneidad cultural de los participantes. Para validar la racionalidad de cada constructo se utilizan ecuaciones estructurales (SEM) ademas de lo que pareciera ser un análisis factorial, sin embargo nos e profundiza en la metodología de los análisis, y se describen en forma muy general las iteraciones y los cambios, no mencionan cuales cambios se hicieron en que items en detalle. Respecto a la consistencia interna, no se menciona referencia para el criterio de alfa = 0,5 (aceptable), otros autores reportan que el alfa de Cronbach debe ser de al menos 0,70 para que sea satisfactorio (Streiner & Norman, 2008). Al analizar las cargas factoriales, estas fueron adecuadas en magnitud, pero se visualizan muchas dimensiones para tan pocos items. En general la literatura recomienda tener por lo menos tres items por cada dimension y acá observamos dimensiones con solo 1 item (MacCallum et al., 1999). Se reportan adecuadamente indicadores de ajuste del modelo (X2, GFI, CFI, RMSEA) y coeficiente de determinación R2 el nos muestra que “pertinencia de la interfaz”, “exactitud de la recomendación” y “pertinencia de la interacción”  explican la mayor cantidad de varianza del modelo en un primer nivel, extrañamente en el último nivel jerárquico del modelo tanto intenciones de compra como de uso explican el mismo porcentaje de varianza, lo cual no es discutido mayormente en el artículo.

La discusión destaca la importancia de los indicadores psicométricos al momento de reconocer que estoy evaluando dimensiones sociales asociadas al comportamiento de usuarios. Al respecto, los autores tuvieron que realizar muchas iteraciones durante el análisis para que éste sea interpretable, por lo que sería adecuado analizar en profundidad las características de la muestra utilizada, quizás como era muy heterogénea en términos culturales y poco balanceada o no suficiente en tamaño. Por otro lado, las dimensiones eran muchas y creo que una mejor idea es buscar nuevos constructos que las agrupen para que por lo menos haya tres items en cada uno de las dimensiones. Finalmente, creo que el aporte del estudio es muy bueno con miras a tener cuestionarios con resultados válidos y confiables que nos permitan medir la percepción y experiencia de los usuarios frente a un sistema de recomendación.

1.	Kirkpatrick DL & Kirkpatrick JD. (2008). *Evaluating training programs*. Berrett-Koehler Publishers, San Francisco. 
2.	Streiner, D. L., & Norman, G. R. (2008). *Health measurement scales: A practical guide to their development and use (4th ed.)*. Oxford, England: Oxford Univer- sity Press. 
3.	MacCallum, R. C., Widaman, K. F., Zhang, S., & Hong, S. (1999). *Sample size in factor analysis*. Psychological Methods, 4(1), 84.

